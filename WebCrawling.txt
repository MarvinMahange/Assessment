import scrapy
from readability import Document
from pymongo import MongoClient

class NewsSpider(scrapy.Spider):
    name = 'news_spider'
    start_urls = ['https://www.theguardian.com/au']

    def parse(self, response):
        # Connect to MongoDB
        client = MongoClient('mongodb+srv://marvinmahange:XXW9uqPbIhc7LAm2@cluster0.jn1xnt5.mongodb.net/?retryWrites=true&w=majority')
        db = client.get_database()

        # Extract information from each news article
        articles = response.css('article.fc-item')
        for article in articles:
            # Extract article headline
            headline = article.css('h3.fc-item__title ::text').get().strip()

            # Extract article URL
            article_url = article.css('h3.fc-item__title a::attr(href)').get()

            # Retrieve and cleanse article text using Readability
            yield scrapy.Request(article_url, callback=self.parse_article, meta={'headline': headline, 'url': article_url})

        # Close MongoDB connection
        client.close()

    def parse_article(self, response):
        # Extract article text using Readability
        article_doc = Document(response.text)
        article_text = article_doc.summary()

        # Extract article author (you may need to adjust this based on the actual HTML structure)
        author = response.css('span.fc-item__author-name ::text').get()
        author_name = author.strip() if author else ''

        # Store the data in MongoDB
        client = MongoClient('mongodb+srv://marvinmahange:XXW9uqPbIhc7LAm2@cluster0.jn1xnt5.mongodb.net/?retryWrites=true&w=majority')
        db = client['TheGuardianNews']

        db.articles.insert_one({
            'headline': response.meta['headline'],
            'url': response.meta['url'],
            'author': author_name,
            'text': article_text
        })
       
        # Close MongoDB connection
        client.close()